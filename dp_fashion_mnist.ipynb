{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential Privacy with the Fashion-MNIST\n",
    "\n",
    "The Fashion-MNIST is a dataset of Zalando's article images. Similarly as the original MNIST dataset, we have 10 classes to clasify in the Fashion-MNIST; 60.000 training images and 10.000 test images. We will see that although these databases have similar specifications, the DP guarantees of the PATE model are different. See the notebook `dp_mnist.ipynb`. As before, we import the basic libraries of Pytorch and Torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "torch.set_printoptions(linewidth=120) # Display options for output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract -Transform - Load (ETL) Step\n",
    "\n",
    "We extract, tranform and load the training data that is going to be used for the teacher's model. The last line splits the training data for each teacher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract, tranform and load the private (train) data\n",
    "\n",
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=True\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "teachers_num = 100                             # Define the number of teachers\n",
    "teachers_batch_size = 30                       # Teachers batch size \n",
    "data_size = len(train_set) // teachers_num    # size of dataset for each teacher\n",
    "\n",
    "\n",
    "teachers_set = torch.utils.data.random_split(train_set, [data_size]*teachers_num) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Network for the Teacher models\n",
    "\n",
    "Our basic neural network has four hidden layers: two convolutional layers and two \"linear\" layers with ReLU activation functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module): \n",
    "    \n",
    "    \"\"\"Network used to train the Teachers\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) # 4*4 is the output per channel of conv2 \n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "    \n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        \n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (3) hidden conv layer\n",
    "        t = self.conv2(t)\n",
    "        t = F.relu(t)\n",
    "        t = F.max_pool2d(t, kernel_size=2, stride=2)\n",
    "        \n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 12*4*4)  # flattens the output of the conv layers\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (5) hidden linear layer\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        \n",
    "        # (6) output layer\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce some classes for managing the training processes and to have cleaner runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE PARAMETERS AND NEEDED CLASSES\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs\n",
    "        \n",
    "\n",
    "class RunManager():\n",
    "    def __init__(self):\n",
    "\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "\n",
    "        self.network = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "        \n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.network = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.network, images)          \n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "    \n",
    "    def end_epoch(self):\n",
    "\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.network.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "        \n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "\n",
    "        for keys,values in self.run_params._asdict().items(): \n",
    "            results[keys] = values\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns') # so we can have a formatted output\n",
    "    \n",
    "        clear_output(wait=True)  # only for jupyter notebook\n",
    "        display(df)              # only for jupyter notebook # outdates the output instead of append\n",
    "        \n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "    \n",
    "    # Auxiliary function. Not intended to be used by outside callers\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        \"\"\" function that outputs the number of correct predictions\"\"\"\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "    \n",
    "    def save(self, fileName):\n",
    "        \n",
    "        pd.DataFrame.from_dict(\n",
    "            self.run_data, orient='columns'\n",
    "        ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with classes \n",
    "\n",
    "Run the next block to train the teachers ensemble. The results are available in `.cvs` and `.json` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>teacher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.797394</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.182544</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.987065</td>\n",
       "      <td>0.598333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.860477</td>\n",
       "      <td>0.651667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.794237</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>0.539354</td>\n",
       "      <td>0.788333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.552582</td>\n",
       "      <td>0.776667</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>100</td>\n",
       "      <td>8</td>\n",
       "      <td>0.500931</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>100</td>\n",
       "      <td>9</td>\n",
       "      <td>0.460467</td>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>0.381967</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     run  epoch      loss  accuracy    lr  batch_size  teacher\n",
       "0      1      1  1.797394  0.300000  0.01          30        0\n",
       "1      1      2  1.182544  0.541667  0.01          30        0\n",
       "2      1      3  0.987065  0.598333  0.01          30        0\n",
       "3      1      4  0.860477  0.651667  0.01          30        0\n",
       "4      1      5  0.794237  0.660000  0.01          30        0\n",
       "..   ...    ...       ...       ...   ...         ...      ...\n",
       "995  100      6  0.539354  0.788333  0.01          30       99\n",
       "996  100      7  0.552582  0.776667  0.01          30       99\n",
       "997  100      8  0.500931  0.805000  0.01          30       99\n",
       "998  100      9  0.460467  0.815000  0.01          30       99\n",
       "999  100     10  0.381967  0.858333  0.01          30       99\n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAINING with RunBuilder and RunMananger\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [teachers_batch_size],\n",
    "    teacher = list(range(0,teachers_num))\n",
    ")\n",
    "\n",
    "m= RunManager()\n",
    "teachers = []  # List of Aggregated teachers (Curator's Model)\n",
    "\n",
    "for run in RunBuilder.get_runs(params): \n",
    "    \n",
    "    network = Network()\n",
    "    teacher_loader = DataLoader(teachers_set[run.teacher], batch_size=run.batch_size)\n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, network, teacher_loader)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        m.begin_epoch()\n",
    "        for batch in teacher_loader:\n",
    "            \n",
    "            images, labels = batch # Get Batch\n",
    "            preds = network(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "    teachers.append(network)  \n",
    "m.save('results_teacher')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proper `batch_size` was obtained after experimenting with different values in the `params` dictionary. We visualized the results of the runs with Tensorboard (below a snipped). In order to see this yourself, you just need to install [tensorboard](https://www.tensorflow.org/tensorboard/), run the previous block and then run in the terminal `tensorboard --logdir=runs`. You should be able to see the tensorboard on your web browser with `http://localhost:6006`. \n",
    "\n",
    "![Tensorboard_snipe](tb1.png \"Tensorboard snipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Teacher\n",
    "\n",
    "We do again the ETL Step for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the public dataset by using 90% of the Test data as train data for the student model\n",
    "# and remaining 10% of the Test data as test data for the student model.\n",
    "\n",
    "test_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data'\n",
    "    ,train=False\n",
    "    ,download=True\n",
    "    ,transform=transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "student_train_set, student_test_set = torch.utils.data.random_split(test_set, [9000,1000]) # this returns two subsets\n",
    "\n",
    "student_train_loader = torch.utils.data.DataLoader(student_train_set, batch_size= 100)\n",
    "student_test_loader = torch.utils.data.DataLoader(student_test_set, batch_size= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICT FUNCTION\n",
    "\n",
    "def predict(network_model, dataloader):\n",
    "    \"\"\" This function predicts labels for a dataset \n",
    "        given the network model and dataloader as inputs. \n",
    "        Outputs a tensor with the probabilities (ps) of the prediction model.\n",
    "        It outputs a rank-1 tensor of size: size(dataloader).\n",
    "    \"\"\"\n",
    "    outputs = torch.zeros(0, dtype=torch.long)\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        output = network_model.forward(images)\n",
    "        output = F.softmax(output, dim=1)\n",
    "        ps = torch.argmax(output, dim=1)\n",
    "        outputs = torch.cat((outputs, ps))\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will obtain a $(0.1, 0)-$differential private learning algorithm. Run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epsilon = 0.2\n",
    "\n",
    "def aggregated_teacher(teachers, dataLoader, epsilon):\n",
    "    \"\"\" Take predictions from individual teacher model and \n",
    "        creates the true labels for the student after adding \n",
    "        laplacian noise to them.\n",
    "        Returns a rank-2 tensor of teachers of size [len(teachers), 9000] and\n",
    "        a numpy.ndarray of size 9000 with student labels.\n",
    "    \"\"\"\n",
    "    preds_teachers = torch.torch.zeros((len(teachers), 9000), dtype=torch.long)\n",
    "    \n",
    "    for i, teacher in enumerate(teachers):\n",
    "        results = predict(teacher, dataLoader)\n",
    "        preds_teachers[i] = results\n",
    "    \n",
    "    labels = np.array([]).astype(int)\n",
    "    for image_preds in np.transpose(preds_teachers):\n",
    "        label_counts = np.bincount(image_preds, minlength=10)\n",
    "        beta = 1 / epsilon\n",
    "\n",
    "        for i in range(len(label_counts)):\n",
    "            label_counts[i] += np.random.laplace(0, beta, 1)\n",
    "\n",
    "        new_label = np.argmax(label_counts)\n",
    "        labels = np.append(labels, new_label)\n",
    "    \n",
    "    return preds_teachers, labels\n",
    "\n",
    "\n",
    "preds_teacher, student_labels = aggregated_teacher(teachers, student_train_loader, epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We relabel now the training data that is going to be used for training the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for parsing images with labels - Student Data Loader\n",
    "\n",
    "train_processing = torch.utils.data.DataLoader(student_train_set, batch_size= 9000)\n",
    "student_images, t_labels = next(iter(train_processing))\n",
    "\n",
    "\n",
    "student_tensor = torch.as_tensor(student_labels)\n",
    "tensor_data = torch.utils.data.TensorDataset(student_images, student_tensor)\n",
    "new_loader =torch.utils.data.DataLoader(tensor_data, batch_size= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a look at how the new labels differ from the true ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new labels are  tensor([1, 4, 4,  ..., 7, 3, 4]) an the old (true) labels are\n",
      "tensor([1, 4, 4,  ..., 9, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"The new labels are \", student_tensor, \"an the old (true) labels are\")\n",
    "\n",
    "print(t_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we train the student model with the new synthatic data, i.e. a relabeled dataset with respect to the teacher ensemble model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.758352</td>\n",
       "      <td>0.713111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.258625</td>\n",
       "      <td>0.904111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.206727</td>\n",
       "      <td>0.924556</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.192338</td>\n",
       "      <td>0.926333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.179398</td>\n",
       "      <td>0.931333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.173945</td>\n",
       "      <td>0.934889</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.159230</td>\n",
       "      <td>0.938222</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.157825</td>\n",
       "      <td>0.941222</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.145647</td>\n",
       "      <td>0.944222</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.140680</td>\n",
       "      <td>0.945556</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy    lr  batch_size\n",
       "0    1      1  0.758352  0.713111  0.01          30\n",
       "1    1      2  0.258625  0.904111  0.01          30\n",
       "2    1      3  0.206727  0.924556  0.01          30\n",
       "3    1      4  0.192338  0.926333  0.01          30\n",
       "4    1      5  0.179398  0.931333  0.01          30\n",
       "5    1      6  0.173945  0.934889  0.01          30\n",
       "6    1      7  0.159230  0.938222  0.01          30\n",
       "7    1      8  0.157825  0.941222  0.01          30\n",
       "8    1      9  0.145647  0.944222  0.01          30\n",
       "9    1     10  0.140680  0.945556  0.01          30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TRAINING Student with Data Generated by Teachers\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [30]\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params): \n",
    "    \n",
    "    student = Network()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=run.lr)\n",
    "    \n",
    "    m.begin_run(run, student, new_loader)\n",
    "\n",
    "    for epoch in range(10):\n",
    "        m.begin_epoch()\n",
    "        for batch in new_loader:\n",
    "            \n",
    "            images, labels = batch # Get Batch\n",
    "            preds = student(images) # Pass Batch\n",
    "            loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
    "            optimizer.zero_grad() # Zero Gradients\n",
    "            loss.backward() # Calculate Gradients\n",
    "            optimizer.step() # Update Weights\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results_student')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `student` network is ready to receive an arbitrary numbers of queries. It guarantees that no past, present or future attack can affect the privacy loss value of `0.1`. The accuracy of the student model in the training set lies between `94%` and `95%`. However, when we test on 1000 public images that belong to the original dataset we obtain only an accuracy of `77%`. Reducing the number of epochs did not improve the accuracy and in fact it reduced to `71%`. In either case, it is better than random guessing, which is `10%` in this case, but less optimal than the result of the original NMIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 77 %\n"
     ]
    }
   ],
   "source": [
    "# Code for testing the accuracy of the student model after training.\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in student_test_loader:\n",
    "        images, labels = data\n",
    "        outputs = student.forward(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
